{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55f8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "FEATURES_DIR = './resnet_features_test/'\n",
    "VALID_EXTENSION = ['jpg', 'jpeg', 'JPG', 'JPEG', 'png', 'PNG', 'Png']\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2a600b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.net = models.resnet50(pretrained=True)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.net.conv1(input)\n",
    "        output = self.net.bn1(output)\n",
    "        output = self.net.relu(output)\n",
    "        output = self.net.maxpool(output)\n",
    "        output = self.net.layer1(output)\n",
    "        output = self.net.layer2(output)\n",
    "        output = self.net.layer3(output)\n",
    "        output = self.net.layer4(output)\n",
    "        output = self.net.avgpool(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fa1abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        VGG = models.vgg16(pretrained=True)\n",
    "        self.feature = VGG.features\n",
    "        self.classifier = nn.Sequential(*list(VGG.classifier.children())[:-3])\n",
    "        pretrained_dict = VGG.state_dict()\n",
    "        model_dict = self.classifier.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.classifier.load_state_dict(model_dict)\n",
    " \n",
    "    def forward(self, x):\n",
    "        output = self.feature(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73194ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net()\n",
    "# model = Encoder()\n",
    "# model = model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910c07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(img_path, saved_path, net, use_gpu):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()]\n",
    "    )\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img)\n",
    "    print('img shape: ', img.shape)\n",
    " \n",
    "    x = Variable(torch.unsqueeze(img, dim=0).float(), requires_grad=False)\n",
    "    print('x shape: ', x.shape)\n",
    " \n",
    "    if use_gpu:\n",
    "        x = x.cuda()\n",
    "        net = net.cuda()\n",
    "    y = net(x).cpu()\n",
    "    y = torch.squeeze(y)\n",
    "    y = y.data.numpy()\n",
    "    print(y.shape)\n",
    "    np.savetxt(saved_path, y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95344efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    tensorTransformer = transforms.ToTensor()\n",
    "    tensorImg = tensorTransformer(img)\n",
    "    print('path:{},  image shape: {}'.format(img_path, tensorImg.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff8deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:{},  image shape: {} ../data/c6_2.png torch.Size([4, 24, 24])\n",
      "path:{},  image shape: {} ../data/c4_1.png torch.Size([4, 39, 39])\n",
      "path:{},  image shape: {} ../data/c6_3.png torch.Size([1, 32, 32])\n",
      "path:{},  image shape: {} ../data/c6_1.png torch.Size([4, 36, 36])\n",
      "path:{},  image shape: {} ../data/c4_2.png torch.Size([4, 20, 24])\n",
      "path:{},  image shape: {} ../data/c2_1.png torch.Size([1, 64, 64])\n",
      "path:{},  image shape: {} ../data/c2_2.png torch.Size([4, 64, 64])\n",
      "path:{},  image shape: {} ../data/c7_1.png torch.Size([1, 22, 15])\n",
      "path:{},  image shape: {} ../data/c5_2.png torch.Size([4, 16, 18])\n",
      "path:{},  image shape: {} ../data/c7_2.png torch.Size([4, 16, 18])\n",
      "path:{},  image shape: {} ../data/c7_3.png torch.Size([4, 20, 22])\n",
      "path:{},  image shape: {} ../data/c5_1.png torch.Size([1, 48, 39])\n",
      "path:{},  image shape: {} ../data/c1_1.png torch.Size([4, 64, 64])\n",
      "path:{},  image shape: {} ../data/c9_8.png torch.Size([4, 48, 48])\n",
      "path:{},  image shape: {} ../data/c7_7.png torch.Size([4, 16, 16])\n",
      "path:{},  image shape: {} ../data/c7_6.png torch.Size([1, 24, 24])\n",
      "path:{},  image shape: {} ../data/c9_9.png torch.Size([2, 44, 44])\n",
      "path:{},  image shape: {} ../data/c3_2.png torch.Size([4, 28, 36])\n",
      "path:{},  image shape: {} ../data/c1_2.png torch.Size([1, 64, 64])\n",
      "path:{},  image shape: {} ../data/c7_4.png torch.Size([4, 20, 20])\n",
      "path:{},  image shape: {} ../data/c7_5.png torch.Size([4, 16, 18])\n",
      "path:{},  image shape: {} ../data/c3_1.png torch.Size([4, 40, 40])\n",
      "path:{},  image shape: {} ../data/c9_7.png torch.Size([2, 30, 30])\n",
      "path:{},  image shape: {} ../data/c7_8.png torch.Size([4, 18, 18])\n",
      "path:{},  image shape: {} ../data/c7_9.png torch.Size([1, 22, 14])\n",
      "path:{},  image shape: {} ../data/c9_6.png torch.Size([2, 68, 68])\n",
      "path:{},  image shape: {} ../data/c9_4.png torch.Size([4, 36, 36])\n",
      "path:{},  image shape: {} ../data/c9_5.png torch.Size([4, 36, 36])\n",
      "path:{},  image shape: {} ../data/c9_12.png torch.Size([1, 40, 40])\n",
      "path:{},  image shape: {} ../data/c9_1.png torch.Size([1, 36, 36])\n",
      "path:{},  image shape: {} ../data/c9_13.png torch.Size([2, 16, 16])\n",
      "path:{},  image shape: {} ../data/c10_1.png torch.Size([1, 22, 20])\n",
      "path:{},  image shape: {} ../data/c9_11.png torch.Size([2, 44, 44])\n",
      "path:{},  image shape: {} ../data/c9_2.png torch.Size([4, 36, 36])\n",
      "path:{},  image shape: {} ../data/c9_3.png torch.Size([4, 36, 36])\n",
      "path:{},  image shape: {} ../data/c9_10.png torch.Size([2, 24, 24])\n",
      "path:{},  image shape: {} ../data/c10_2.png torch.Size([4, 30, 30])\n",
      "path:{},  image shape: {} ../data/c11_4.png torch.Size([1, 28, 28])\n",
      "path:{},  image shape: {} ../data/c8_2.png torch.Size([1, 48, 48])\n",
      "path:{},  image shape: {} ../data/c11_3.png torch.Size([4, 60, 60])\n",
      "path:{},  image shape: {} ../data/c11_2.png torch.Size([1, 64, 64])\n",
      "path:{},  image shape: {} ../data/c8_3.png torch.Size([1, 48, 48])\n",
      "path:{},  image shape: {} ../data/c8_1.png torch.Size([4, 48, 48])\n",
      "path:{},  image shape: {} ../data/c11_1.png torch.Size([2, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "x = os.walk(data_dir)\n",
    "for path, dirctory, filelist in x:\n",
    "    for filename in filelist:\n",
    "        file_glob = os.path.join(path, filename)\n",
    "        is_valid = False\n",
    "        for ext in VALID_EXTENSION:\n",
    "            if file_glob.endswith(ext):\n",
    "                is_valid = True\n",
    "                break\n",
    "        if is_valid:\n",
    "            preprocessImage(file_glob)\n",
    "#             print(file_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83590c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/c6_2.png', '../data/c4_1.png', '../data/c6_3.png', '../data/c6_1.png', '../data/c4_2.png', '../data/.DS_Store', '../data/c2_1.png', '../data/c2_2.png', '../data/c7_1.png', '../data/c5_2.png', '../data/c7_2.png', '../data/c7_3.png', '../data/c5_1.png', '../data/c1_1.png', '../data/c9_8.png', '../data/c7_7.png', '../data/c7_6.png', '../data/c9_9.png', '../data/c3_2.png', '../data/c1_2.png', '../data/c7_4.png', '../data/c7_5.png', '../data/c3_1.png', '../data/c9_7.png', '../data/c7_8.png', '../data/c7_9.png', '../data/c9_6.png', '../data/c9_4.png', '../data/c9_5.png', '../data/c9_12.png', '../data/c9_1.png', '../data/c9_13.png', '../data/c10_1.png', '../data/c9_11.png', '../data/c9_2.png', '../data/c9_3.png', '../data/c9_10.png', '../data/c10_2.png', '../data/c11_4.png', '../data/c8_2.png', '../data/c11_3.png', '../data/c11_2.png', '../data/c8_3.png', '../data/c8_1.png', '../data/c11_1.png']\n",
      "x_path: ../data/c6_2.png\n",
      "x_path: ../data/c4_1.png\n",
      "x_path: ../data/c6_3.png\n",
      "x_path: ../data/c6_1.png\n",
      "x_path: ../data/c4_2.png\n",
      "x_path: ../data/.DS_Store\n",
      "x_path: ../data/c2_1.png\n",
      "x_path: ../data/c2_2.png\n",
      "x_path: ../data/c7_1.png\n",
      "x_path: ../data/c5_2.png\n",
      "x_path: ../data/c7_2.png\n",
      "x_path: ../data/c7_3.png\n",
      "x_path: ../data/c5_1.png\n",
      "x_path: ../data/c1_1.png\n",
      "x_path: ../data/c9_8.png\n",
      "x_path: ../data/c7_7.png\n",
      "x_path: ../data/c7_6.png\n",
      "x_path: ../data/c9_9.png\n",
      "x_path: ../data/c3_2.png\n",
      "x_path: ../data/c1_2.png\n",
      "x_path: ../data/c7_4.png\n",
      "x_path: ../data/c7_5.png\n",
      "x_path: ../data/c3_1.png\n",
      "x_path: ../data/c9_7.png\n",
      "x_path: ../data/c7_8.png\n",
      "x_path: ../data/c7_9.png\n",
      "x_path: ../data/c9_6.png\n",
      "x_path: ../data/c9_4.png\n",
      "x_path: ../data/c9_5.png\n",
      "x_path: ../data/c9_12.png\n",
      "x_path: ../data/c9_1.png\n",
      "x_path: ../data/c9_13.png\n",
      "x_path: ../data/c10_1.png\n",
      "x_path: ../data/c9_11.png\n",
      "x_path: ../data/c9_2.png\n",
      "x_path: ../data/c9_3.png\n",
      "x_path: ../data/c9_10.png\n",
      "x_path: ../data/c10_2.png\n",
      "x_path: ../data/c11_4.png\n",
      "x_path: ../data/c8_2.png\n",
      "x_path: ../data/c11_3.png\n",
      "x_path: ../data/c11_2.png\n",
      "x_path: ../data/c8_3.png\n",
      "x_path: ../data/c8_1.png\n",
      "x_path: ../data/c11_1.png\n",
      "before transform:  torch.Size([2, 34, 34])\n",
      "ch1: tensor([[0.6784, 0.6784, 0.6784,  ..., 0.6784, 0.6784, 0.6784],\n",
      "        [0.6784, 0.6784, 0.6784,  ..., 0.6784, 0.6784, 0.6784],\n",
      "        [0.6784, 0.6784, 0.6784,  ..., 0.6784, 0.6784, 0.6784],\n",
      "        ...,\n",
      "        [0.6784, 0.6784, 0.6784,  ..., 0.6784, 0.6784, 0.6784],\n",
      "        [0.6784, 0.6784, 0.6784,  ..., 0.6784, 0.6784, 0.6784],\n",
      "        [0.6784, 0.6784, 0.6784,  ..., 0.6784, 0.6784, 0.6784]])\n",
      "ch2: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g2/jy_8z3fs28526pxbf3l1gbdm0000gn/T/ipykernel_75234/1542230848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     print(fx_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mlen_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlen_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/g2/jy_8z3fs28526pxbf3l1gbdm0000gn/T/ipykernel_75234/1610767288.py\u001b[0m in \u001b[0;36mextractor\u001b[0;34m(img_path, saved_path, net, use_gpu)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ch1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ch2:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ch3:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ch4:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "x = os.walk(DATA_DIR)\n",
    "for path, directory, filelist in x:\n",
    "#     print(path)\n",
    "#     print(directory)\n",
    "#     print(filelist)\n",
    "#     print('---')\n",
    "    for filename in filelist:\n",
    "        file_glob = os.path.join(path, filename)\n",
    "        file_list.extend(glob.glob(file_glob))\n",
    "        \n",
    "# print(file_list)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "for index, x_path in enumerate(file_list):\n",
    "    file_name = x_path.split('/')[-1]\n",
    "    fx_path = os.path.join(FEATURES_DIR, file_name + '.txt')\n",
    "    print(fx_path)\n",
    "    extractor(x_path, fx_path, model, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac2e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
